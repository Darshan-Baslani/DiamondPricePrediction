import pandas as pd
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv('data/gemstone.csv')
df.head()


df = df.drop('id', axis=1)
df = df.drop('x', axis=1)
df = df.drop('y', axis=1)
df = df.drop('z', axis=1)
df.head()


X = df.iloc[:, :-1]
y = df.iloc[:, -1:]


cat_features = df.columns[df.dtypes == 'object']
num_features = df.columns[df.dtypes != 'object']
num_features = num_features.drop('price')
cat_features, num_features


# For Scaling the data
from sklearn.preprocessing import StandardScaler

# For Categorical to Numerical transformation
from sklearn.preprocessing import OrdinalEncoder

# For Creating Pipleines
from sklearn.pipeline import Pipeline

# Combining Pipelines
from sklearn.compose import ColumnTransformer

# Handling Missing values
from sklearn.impute import SimpleImputer


num_pipeline = Pipeline(
    steps= [
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ]
)

cat_pipeline = Pipeline(
    steps= [
        ('impute', SimpleImputer(strategy='most_frequent')),
        ('encode', OrdinalEncoder()),
        ('scaler', StandardScaler())
    ]
)

preprocessor = ColumnTransformer([
        ('num_pipeline', num_pipeline, num_features),
        ('cat_pipeline', cat_pipeline, cat_features)
    ]
)


# spliting the data into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=404)


X_train = pd.DataFrame(preprocessor.fit_transform(X_train), columns=preprocessor.get_feature_names_out())
X_test = pd.DataFrame(preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())
X_train 


# For creating models
from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet
from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor
from xgboost import XGBRegressor

# For model evolution
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error



model_list = ['LinearRegression', 'Lasso', 'Ridge', 'ElasticNet', 'GradientBoostingRegressor', 'AdaBoostRegressor', 'BaggingRegressor', 'XGBRegressor']
def model_evalution(model, i):
    y_pred = model.predict(X_test)
    print("\n\n")
    print(model_list[i])
    print("R2 Score: " + str(r2_score(y_test, y_pred)))
    print("mean_absolute_error: " + str(mean_absolute_error(y_test, y_pred)))
    print("mean_squared_error: " + str(mean_squared_error(y_test, y_pred)))


#Training the models
models = {
    'LinearRegression' : LinearRegression(),
    'Lasso' : Lasso(),
    'Ridge' : Ridge(),
    'ElasticNet' : ElasticNet(),
    'GradientBoostingRegressor' : GradientBoostingRegressor(),
    'AdaBoostRegressor' : AdaBoostRegressor(),
    'BaggingRegressor' : BaggingRegressor(), 
    'XGBRegressor' : XGBRegressor()
}

i=0
for model in models:
    curr_model = models[model]
    curr_model.fit(X_train, y_train)
    model_evalution(curr_model, i)
    i+=1
